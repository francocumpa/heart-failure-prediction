# Heart Failure Prediction Project

## DescripciÃ³n

Este proyecto es una aplicaciÃ³n web para predecir enfermedades cardÃ­acas en un paciente basÃ¡ndose en una serie de atributos mÃ©dicos. La aplicaciÃ³n cuenta con un backend de Machine Learning que expone una API y un frontend interactivo para realizar las predicciones.

## Demo en Vivo (Hugging Face Spaces ðŸ¤—)

Puedes probar la aplicaciÃ³n directamente en el siguiente enlace:

[Probar la demo en vivo](https://franco3030-heart-failure-prediction.hf.space/?__theme=system&deep_link=ipxpizTHR54)

## TecnologÃ­as Utilizadas

- **Backend:** Python, FastAPI, Pandas, Scikit-learn, Joblib, Uvicorn
- **Frontend:** Gradio, Requests
- **ContenerizaciÃ³n:** Docker

## Estructura del Proyecto

```
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb        # Entrenamiento y evaluacion del modelo
â””â”€â”€ src/
    â”œâ”€â”€ backend/              # LÃ³gica del modelo y la API
    |   â”œâ”€â”€ Dockerfile        # Define el entorno para ejecutar el backend
    â”‚   â”œâ”€â”€ api.py            # Endpoint de la API (FastAPI)
    â”‚   â”œâ”€â”€ model.py          # Carga del modelo y lÃ³gica de predicciÃ³n
    â”‚   â”œâ”€â”€ requirements.txt  # Dependencias del backend
    â”‚   â””â”€â”€ models/           # Modelos pre-entrenados
    â””â”€â”€ frontend/
        â””â”€â”€ app.py            # Interfaz de usuario (Gradio)
```

## InstalaciÃ³n y Uso

Existen dos formas de ejecutar este proyecto: utilizando Docker (recomendado) o de forma local.

### OpciÃ³n 1: EjecuciÃ³n con Docker (Recomendado)

Esta opciÃ³n ejecuta el backend en un contenedor Docker.

1.  **Cambiamos de directorio al backend:**
    ```bash
    cd src/backend
    ```

2.  **Construir la imagen de Docker:**
    ```bash
    docker build -t heart-failure-predictor .
    ```

3.  **Ejecutar el contenedor:**
    ```bash
    docker run -p 8000:8000 heart-failure-predictor
    ```
    El backend estarÃ¡ disponible en `http://localhost:8000`.

### OpciÃ³n 2: EjecuciÃ³n Local

1.  **Clonar el repositorio (si aplica).**

2.  **Instalar dependencias del backend:**
    ```bash
    pip install -r src/backend/requirements.txt
    ```

3.  **Instalar dependencias del frontend:**
    ```bash
    pip install gradio requests
    ```

4.  **Ejecutar el backend:**
    Navega al directorio `src/backend` y ejecuta:
    ```bash
    uvicorn api:app --host 0.0.0.0 --port 8000
    ```

5.  **Ejecutar el frontend:**
    En una nueva terminal, ejecuta:
    ```bash
    python src/frontend/app.py
    ```
    La interfaz de Gradio se abrirÃ¡ en tu navegador.

# Monitoreo y Versionado de Modelos

## 1. Monitoreo
El monitoreo debe realizarse en tres niveles:

1. **Modelo de Machine Learning**  
   - Seguimiento del rendimiento.  
   - Control de mÃ©tricas y posibles sesgos.  

2. **Infraestructura**  
   - Estado de los servicios.  
   - Consumo de recursos y disponibilidad.  

3. **Valor para el negocio**  
   - Evaluar si los resultados generan impacto real.  
   - Usar los hallazgos para tomar decisiones estratÃ©gicas.  

## 2. Versionado
Para un control eficiente de versiones de modelos se recomienda utilizar herramientas de MLOps como:

- **MLflow**  
- **Databricks**  
- Otros sistemas de gestiÃ³n de experimentos  

Estas plataformas permiten:  
- Registrar cada versiÃ³n del modelo.  
- Comparar mÃ©tricas entre iteraciones.  
- Reproducir experimentos y despliegues de manera confiable.


